{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50b41f4-dfb7-4534-b1dd-21246337c780",
   "metadata": {},
   "source": [
    "# 8510 HW6 Part1 - David Tung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ab516fea-2310-4a1b-ab5a-b0d3cac6c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from file\n",
    "file_path = './spam2.csv'\n",
    "spam_data = pd.read_csv(file_path)\n",
    "np_spam_data = np.array(spam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7105a091-a39e-4651-b2b7-2e0e136d7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (top 70%) and test (other 30%) \n",
    "split_index = int(0.7 * len(spam_data))\n",
    "train_data = np_spam_data[:split_index]\n",
    "test_data = np_spam_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a21d45f6-4fc1-4876-8e0e-b140500b7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = np.array([sum(train_data[:,0]==0), sum(train_data[:,0]==1)])\n",
    "prior_prob = class_count/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0a945fb0-c8c8-4b02-8d74-265a074451d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesUtils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Init function\n",
    "        \"\"\"\n",
    "        self.t_class_f = None # target frequency\n",
    "        self.feature_f = None\n",
    "        rows = 0\n",
    "        columes = 0\n",
    "        results = []\n",
    "        self.t_class_p = None # probability\n",
    "        self.feature_p = None\n",
    "\n",
    "    def probabilities(self, feature):\n",
    "        \"\"\"\n",
    "        Calculate the probabilities\n",
    "        \"\"\"\n",
    "        n_rows, n_columes = feature.shape\n",
    "        self.t_class_p = self.t_class_f/n_rows\n",
    "        for i in range(n_columes):\n",
    "            num_unique_feature_val = len(np.unique(feature[:, i]))\n",
    "            for f in range(num_unique_feature_val):\n",
    "                ##\n",
    "                ## itrate classes 0,1 \n",
    "                for cls in [0,1]:\n",
    "                    self.feature_p[i, f, cls] = \\\n",
    "                     (self.feature_f[i, f, cls])/(self.t_class_f[cls])\n",
    "\n",
    "    def fit_model(self, feature, y):\n",
    "        \"\"\" \n",
    "        Train the NB model \n",
    "        \"\"\"\n",
    "        n_rows, n_features = feature.shape\n",
    "        self.t_class_f = np.zeros(2)\n",
    "        ##\n",
    "        ## frequncy array of [num of features, num of feature vals, num of target class]\n",
    "        ##\n",
    "        self.feature_f = \\\n",
    "            np.zeros((n_features, len(np.unique(feature)), 2))\n",
    "        self.t_class_p = np.zeros(2)\n",
    "\n",
    "        ##\n",
    "        ## probablity array of [num of features, num of feature vals, num of target class]\n",
    "        ##\n",
    "        self.feature_p = \\\n",
    "            np.zeros((n_features, len(np.unique(feature)), 2))\n",
    "        for cls in [0,1]: # iterate classes\n",
    "            feature_c = feature[y == cls]\n",
    "            self.t_class_f[cls] = feature_c.shape[0]\n",
    "            for fi in range(n_features): # iterate feature index\n",
    "                feature_values = np.unique(feature[:, fi])\n",
    "                for fv in feature_values: # iterate feature val\n",
    "                    self.feature_f[fi, fv, cls] = np.sum(feature_c[:, fi] == fv)\n",
    "                ##print(self.t_class_p)\n",
    "        self.probabilities(feature)\n",
    "\n",
    "    def predict_results(self, features):\n",
    "        \"\"\"\n",
    "        Predict result based on test features\n",
    "        \"\"\"\n",
    "        pred = []\n",
    "        for sample in features:\n",
    "            posteriors = []\n",
    "            ##\n",
    "            ## ite target class 0,1\n",
    "            for cls in [0,1]:\n",
    "                posterior = self.t_class_p[cls]\n",
    "                for idx, val in enumerate(sample):\n",
    "                    posterior = \\\n",
    "                        posterior * self.feature_p[idx, val, cls]\n",
    "                posteriors.append(posterior)\n",
    "            pred.append([0,1][np.argmax(posteriors)])\n",
    "            # print(pred)\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "5f545ec7-2ed5-458e-8f2b-23f799535a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayesUtils = NaiveBayesUtils()\n",
    "features = train_data[:, 1:]  # Features\n",
    "target = train_data[:, 0]   # Labels\n",
    "naiveBayesUtils.fit_model(features, target)\n",
    "\n",
    "testing_data_features = test_data[:, 1:]  # Features from testing\n",
    "y_pred = naiveBayesUtils.predict_results(testing_data_features)\n",
    "\n",
    "actual = np.array([test_data[:, 0]]).T[:,0]\n",
    "pred = np.array([y_pred]).T[:,0]\n",
    "\n",
    "TP = sum((actual==1) & (pred ==1))\n",
    "TN = sum((actual==0) & (pred ==0))\n",
    "FN = sum((actual==1) & (pred ==0))\n",
    "FP = sum((actual==0) & (pred ==1))\n",
    "\n",
    "cm = np.array([[TP, FN],\n",
    "               [FP, TN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57fd51-b625-43da-be56-98c274bfea2d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "fb880b29-7272-4d76-ab81-9bd8c7da51ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts [0, 1]:\n",
      " [460 454]\n",
      "\n",
      "Prior Probabilities [0, 1]:\n",
      " [0.50328228 0.49671772]\n",
      "\n",
      "Confusion Matrix[[TP,FN],[FP,TN]]: \n",
      " [[168  31]\n",
      " [  7 186]]\n",
      "\n",
      "Accuracy= 0.9030612244897959\n",
      "Recall= 0.8442211055276382\n",
      "Precision= 0.96\n",
      "F1= 0.8983957219251336\n"
     ]
    }
   ],
   "source": [
    "Accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1 = 2*Precision*Recall/(Precision+Recall)\n",
    "print(f\"Class Counts [0, 1]:\\n {class_count}\\n\")\n",
    "print(f\"Prior Probabilities [0, 1]:\\n {prior_prob}\\n\")\n",
    "print(f\"Confusion Matrix[[TP,FN],[FP,TN]]: \\n {cm}\\n\")\n",
    "print(f\"Accuracy= {Accuracy}\")\n",
    "print(f\"Recall= {Recall}\")\n",
    "print(f\"Precision= {Precision}\")\n",
    "print(f\"F1= {F1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be682a39-bdec-4034-9247-8d5d9b7b449c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
